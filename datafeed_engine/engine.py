import logging
import schedule
import time
import sys
import os
import argparse
from datetime import datetime, timedelta
from typing import List, Dict, Optional
import threading
import pandas as pd

# æ”¯æŒç›¸å¯¹å¯¼å…¥å’Œç»å¯¹å¯¼å…¥
try:
    from .database import DatabaseManager
    from .fetchers import OKXDataFetcher, BinanceDataFetcher, YahooDataFetcher, TushareDataFetcher
except ImportError:
    # å½“ä½œä¸ºè„šæœ¬ç›´æ¥è¿è¡Œæ—¶ï¼Œä½¿ç”¨ç»å¯¹å¯¼å…¥
    sys.path.append(os.path.dirname(os.path.abspath(__file__)))
    from database import DatabaseManager
    from fetchers import OKXDataFetcher, BinanceDataFetcher, YahooDataFetcher, TushareDataFetcher

class DataFeedEngine:
    """æ•°æ®è·å–å¼•æ“"""
    
    def __init__(self, db_path: str = "market_data.db", config_path: str = "config.ini"):
        """
        åˆå§‹åŒ–æ•°æ®è·å–å¼•æ“
        
        Args:
            db_path: æ•°æ®åº“æ–‡ä»¶è·¯å¾„
            config_path: é…ç½®æ–‡ä»¶è·¯å¾„
        """
        self.db_manager = DatabaseManager(db_path)
        self.config_path = config_path
        self.logger = self._setup_logger()
        
        # åˆå§‹åŒ–æ•°æ®è·å–å™¨
        self.fetchers = {
            'okx': OKXDataFetcher(config_path),
            'binance': BinanceDataFetcher(config_path),
            'yahoo': YahooDataFetcher(config_path),
            'tushare': TushareDataFetcher(config_path)
        }
        
        # è¿è¡ŒçŠ¶æ€
        self.running = False
        self.scheduler_thread = None
        
        # é»˜è®¤é…ç½®
        self.default_config = {
            'crypto_symbols': ['BTC/USDT', 'ETH/USDT'],
            'us_stocks': ['AAPL', 'TSLA', 'GOOGL'],
            'a_stocks': ['000001.SZ', '600000.SH'],
            'timeframes': ['1m', '5m', '15m', '30m', '1h', '2h', '1d'],
            'crypto_exchanges': ['okx', 'binance'],
            'update_interval_minutes': 60  # æ¯å°æ—¶æ›´æ–°ä¸€æ¬¡
        }
    
    def _setup_logger(self):
        """è®¾ç½®æ—¥å¿—è®°å½•å™¨"""
        logger = logging.getLogger('DataFeedEngine')
        if not logger.handlers:
            handler = logging.StreamHandler()
            formatter = logging.Formatter(
                '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
            )
            handler.setFormatter(formatter)
            logger.addHandler(handler)
            logger.setLevel(logging.INFO)
        return logger
    
    def fetch_crypto_data(self, symbols: List[str], timeframes: List[str], 
                         exchanges: List[str] = None, days: int = 7) -> Dict[str, int]:
        """
        è·å–åŠ å¯†è´§å¸æ•°æ®
        
        Args:
            symbols: äº¤æ˜“å¯¹åˆ—è¡¨
            timeframes: æ—¶é—´å‘¨æœŸåˆ—è¡¨
            exchanges: äº¤æ˜“æ‰€åˆ—è¡¨
            days: è·å–å¤šå°‘å¤©çš„æ•°æ®
            
        Returns:
            å„äº¤æ˜“æ‰€æ’å…¥çš„æ•°æ®ç»Ÿè®¡
        """
        if exchanges is None:
            exchanges = ['okx', 'binance']
        
        results = {}
        end_time = datetime.now()
        start_time = end_time - timedelta(days=days)
        
        for exchange in exchanges:
            if exchange not in self.fetchers:
                continue
            
            fetcher = self.fetchers[exchange]
            results[exchange] = 0
            
            for symbol in symbols:
                for timeframe in timeframes:
                    try:
                        self.logger.info(f"è·å– {exchange} {symbol} {timeframe} æ•°æ®...")
                        
                        # æ£€æŸ¥æ˜¯å¦å·²æœ‰æ•°æ®ï¼Œå®ç°å¢é‡æ›´æ–°
                        latest_timestamp = self.db_manager.get_latest_timestamp(
                            symbol, exchange, timeframe
                        )
                        
                        if latest_timestamp:
                            # ä»æœ€æ–°æ—¶é—´æˆ³å¼€å§‹è·å–
                            fetch_start_time = datetime.fromtimestamp(latest_timestamp / 1000)
                            # æ·»åŠ ä¸€ä¸ªæ—¶é—´å‘¨æœŸçš„åç§»é¿å…é‡å¤
                            fetch_start_time += self._get_timeframe_delta(timeframe)
                        else:
                            fetch_start_time = start_time
                        
                        # å¦‚æœå¼€å§‹æ—¶é—´å·²ç»è¶…è¿‡ç»“æŸæ—¶é—´ï¼Œè·³è¿‡
                        if fetch_start_time >= end_time:
                            self.logger.info(f"{exchange} {symbol} {timeframe} æ•°æ®å·²æ˜¯æœ€æ–°")
                            continue
                        
                        # è·å–æ•°æ®
                        data = fetcher.fetch_data(
                            symbol=symbol,
                            timeframe=timeframe,
                            start_time=fetch_start_time,
                            end_time=end_time,
                            limit=1000
                        )
                        
                        # ä¿å­˜åˆ°æ•°æ®åº“
                        if not data.empty:
                            inserted_count = self.db_manager.save_data(
                                data, symbol, exchange, timeframe
                            )
                            results[exchange] += inserted_count
                            self.logger.info(f"æ’å…¥ {inserted_count} æ¡ {exchange} {symbol} {timeframe} æ•°æ®")
                        
                        # é¿å…APIé™åˆ¶
                        time.sleep(0.5)
                        
                    except Exception as e:
                        self.logger.error(f"è·å– {exchange} {symbol} {timeframe} æ•°æ®å¤±è´¥: {e}")
                        continue
        
        return results
    
    def fetch_us_stock_data(self, symbols: List[str], timeframes: List[str], 
                           days: int = 30) -> int:
        """
        è·å–ç¾è‚¡æ•°æ®
        
        Args:
            symbols: è‚¡ç¥¨ä»£ç åˆ—è¡¨
            timeframes: æ—¶é—´å‘¨æœŸåˆ—è¡¨
            days: è·å–å¤šå°‘å¤©çš„æ•°æ®
            
        Returns:
            æ’å…¥çš„æ•°æ®æ¡æ•°
        """
        fetcher = self.fetchers['yahoo']
        total_inserted = 0
        
        end_time = datetime.now()
        start_time = end_time - timedelta(days=days)
        
        for symbol in symbols:
            for timeframe in timeframes:
                try:
                    self.logger.info(f"è·å–Yahoo Finance {symbol} {timeframe} æ•°æ®...")
                    
                    # æ£€æŸ¥æ˜¯å¦å·²æœ‰æ•°æ®
                    latest_timestamp = self.db_manager.get_latest_timestamp(
                        symbol, 'yahoo', timeframe
                    )
                    
                    if latest_timestamp:
                        fetch_start_time = datetime.fromtimestamp(latest_timestamp / 1000)
                        fetch_start_time += self._get_timeframe_delta(timeframe)
                    else:
                        fetch_start_time = start_time
                    
                    if fetch_start_time >= end_time:
                        self.logger.info(f"Yahoo Finance {symbol} {timeframe} æ•°æ®å·²æ˜¯æœ€æ–°")
                        continue
                    
                    # è·å–æ•°æ®
                    data = fetcher.fetch_data(
                        symbol=symbol,
                        timeframe=timeframe,
                        start_time=fetch_start_time,
                        end_time=end_time
                    )
                    
                    # ä¿å­˜åˆ°æ•°æ®åº“
                    if not data.empty:
                        inserted_count = self.db_manager.save_data(
                            data, symbol, 'yahoo', timeframe
                        )
                        total_inserted += inserted_count
                        self.logger.info(f"æ’å…¥ {inserted_count} æ¡Yahoo Finance {symbol} {timeframe} æ•°æ®")
                    
                    time.sleep(1)  # Yahoo Finance APIé™åˆ¶
                    
                except Exception as e:
                    self.logger.error(f"è·å–Yahoo Finance {symbol} {timeframe} æ•°æ®å¤±è´¥: {e}")
                    continue
        
        return total_inserted
    
    def fetch_a_stock_data(self, symbols: List[str], timeframes: List[str] = ['1d'], 
                          days: int = 365) -> int:
        """
        è·å–Aè‚¡æ•°æ®ï¼ˆæ‰¹é‡ç‰ˆæœ¬ï¼‰
        
        Args:
            symbols: è‚¡ç¥¨ä»£ç åˆ—è¡¨
            timeframes: æ—¶é—´å‘¨æœŸåˆ—è¡¨(Tushareä¸»è¦æ”¯æŒæ—¥çº¿)
            days: è·å–å¤šå°‘å¤©çš„æ•°æ®
            
        Returns:
            æ’å…¥çš„æ•°æ®æ¡æ•°
        """
        total_inserted = 0
        
        for symbol in symbols:
            for timeframe in timeframes:
                try:
                    # ä½¿ç”¨å•è‚¡ç¥¨è·å–æ–¹æ³•ï¼Œé¿å…ä»£ç é‡å¤
                    inserted_count = self.fetch_single_stock_data(
                        symbol=symbol,
                        exchange='tushare',
                        timeframe=timeframe,
                        days=days
                    )
                    total_inserted += inserted_count
                    
                    # Tushare APIé™åˆ¶
                    time.sleep(1)
                    
                except Exception as e:
                    self.logger.error(f"è·å–Aè‚¡æ•°æ®å¤±è´¥ {symbol} {timeframe}: {e}")
                    continue
        
        return total_inserted
    
    def fetch_single_stock_data(self, symbol: str, exchange: str = 'tushare', 
                               timeframe: str = '1d', days: int = 365) -> int:
        """
        è·å–å•åªè‚¡ç¥¨æ•°æ®
        
        Args:
            symbol: è‚¡ç¥¨ä»£ç  (å¦‚ '000001.SZ')
            exchange: äº¤æ˜“æ‰€ ('tushare', 'yahoo')
            timeframe: æ—¶é—´å‘¨æœŸ
            days: è·å–å¤šå°‘å¤©çš„æ•°æ®
            
        Returns:
            æ’å…¥çš„æ•°æ®æ¡æ•°
        """
        if exchange not in self.fetchers:
            self.logger.error(f"ä¸æ”¯æŒçš„äº¤æ˜“æ‰€: {exchange}")
            return 0
            
        fetcher = self.fetchers[exchange]
        
        end_time = datetime.now()
        start_time = end_time - timedelta(days=days)
        
        try:
            # æ£€æŸ¥æ˜¯å¦å·²æœ‰æ•°æ®
            latest_timestamp = self.db_manager.get_latest_timestamp(
                symbol, exchange, timeframe
            )
            
            if latest_timestamp:
                fetch_start_time = datetime.fromtimestamp(latest_timestamp / 1000)
                fetch_start_time += self._get_timeframe_delta(timeframe)
            else:
                fetch_start_time = start_time
            
            if fetch_start_time >= end_time:
                self.logger.info(f"{exchange} {symbol} {timeframe} æ•°æ®å·²æ˜¯æœ€æ–°")
                return 0
            
            # è·å–æ•°æ®
            data = fetcher.fetch_data(
                symbol=symbol,
                timeframe=timeframe,
                start_time=fetch_start_time,
                end_time=end_time
            )
            
            # ä¿å­˜åˆ°æ•°æ®åº“
            if not data.empty:
                inserted_count = self.db_manager.save_data(
                    data, symbol, exchange, timeframe
                )
                return inserted_count
            else:
                return 0
                
        except Exception as e:
            self.logger.error(f"è·å– {exchange} {symbol} {timeframe} æ•°æ®å¤±è´¥: {e}")
            return 0
    
    def fetch_all_data(self, config: Dict = None) -> Dict[str, int]:
        """
        è·å–æ‰€æœ‰é…ç½®çš„æ•°æ®
        
        Args:
            config: è‡ªå®šä¹‰é…ç½®ï¼Œå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨é»˜è®¤é…ç½®
            
        Returns:
            æ•°æ®è·å–ç»Ÿè®¡
        """
        if config is None:
            config = self.default_config
        
        results = {'crypto': {}, 'us_stocks': 0, 'a_stocks': 0}
        
        # è·å–åŠ å¯†è´§å¸æ•°æ®
        if 'crypto_symbols' in config and 'timeframes' in config:
            crypto_results = self.fetch_crypto_data(
                symbols=config['crypto_symbols'],
                timeframes=config['timeframes'],
                exchanges=config.get('crypto_exchanges', ['okx', 'binance'])
            )
            results['crypto'] = crypto_results
        
        # è·å–ç¾è‚¡æ•°æ®
        if 'us_stocks' in config:
            us_results = self.fetch_us_stock_data(
                symbols=config['us_stocks'],
                timeframes=config.get('timeframes', ['1d'])
            )
            results['us_stocks'] = us_results
        
        # è·å–Aè‚¡æ•°æ®
        if 'a_stocks' in config:
            a_results = self.fetch_a_stock_data(
                symbols=config['a_stocks'],
                timeframes=['1d']  # Tushareä¸»è¦æ”¯æŒæ—¥çº¿
            )
            results['a_stocks'] = a_results
        
        return results
    
    def start_scheduler(self, config: Dict = None):
        """
        å¯åŠ¨å®šæ—¶ä»»åŠ¡
        
        Args:
            config: è‡ªå®šä¹‰é…ç½®
        """
        if self.running:
            self.logger.warning("è°ƒåº¦å™¨å·²åœ¨è¿è¡Œ")
            return
        
        if config is None:
            config = self.default_config
        
        # è®¾ç½®å®šæ—¶ä»»åŠ¡
        interval_minutes = config.get('update_interval_minutes', 60)
        schedule.every(interval_minutes).minutes.do(self._scheduled_fetch, config)
        
        self.running = True
        
        # å¯åŠ¨è°ƒåº¦å™¨çº¿ç¨‹
        self.scheduler_thread = threading.Thread(target=self._run_scheduler)
        self.scheduler_thread.daemon = True
        self.scheduler_thread.start()
        
        self.logger.info(f"æ•°æ®è·å–è°ƒåº¦å™¨å·²å¯åŠ¨ï¼Œæ›´æ–°é—´éš”: {interval_minutes} åˆ†é’Ÿ")
    
    def stop_scheduler(self):
        """åœæ­¢å®šæ—¶ä»»åŠ¡"""
        self.running = False
        schedule.clear()
        
        if self.scheduler_thread:
            self.scheduler_thread.join(timeout=5)
        
        self.logger.info("æ•°æ®è·å–è°ƒåº¦å™¨å·²åœæ­¢")
    
    def _run_scheduler(self):
        """è¿è¡Œè°ƒåº¦å™¨"""
        while self.running:
            schedule.run_pending()
            time.sleep(30)  # æ¯30ç§’æ£€æŸ¥ä¸€æ¬¡
    
    def _scheduled_fetch(self, config: Dict):
        """å®šæ—¶è·å–æ•°æ®"""
        try:
            self.logger.info("å¼€å§‹å®šæ—¶æ•°æ®è·å–...")
            results = self.fetch_all_data(config)
            self.logger.info(f"å®šæ—¶æ•°æ®è·å–å®Œæˆ: {results}")
        except Exception as e:
            self.logger.error(f"å®šæ—¶æ•°æ®è·å–å¤±è´¥: {e}")
    
    def _get_timeframe_delta(self, timeframe: str) -> timedelta:
        """è·å–æ—¶é—´å‘¨æœŸå¯¹åº”çš„æ—¶é—´é—´éš”"""
        timeframe_map = {
            '1m': timedelta(minutes=1),
            '5m': timedelta(minutes=5),
            '15m': timedelta(minutes=15),
            '30m': timedelta(minutes=30),
            '1h': timedelta(hours=1),
            '2h': timedelta(hours=2),
            '1d': timedelta(days=1)
        }
        return timeframe_map.get(timeframe, timedelta(minutes=1))
    
    def get_database_info(self) -> dict:
        """è·å–æ•°æ®åº“ä¿¡æ¯"""
        return self.db_manager.get_database_info()
    
    def get_data(self, symbol: str, exchange: str, timeframe: str,
                start_time: Optional[datetime] = None, end_time: Optional[datetime] = None,
                limit: Optional[int] = None) -> pd.DataFrame:
        """
        ä»æ•°æ®åº“è·å–æ•°æ®
        
        Args:
            symbol: äº¤æ˜“å¯¹ç¬¦å·
            exchange: äº¤æ˜“æ‰€
            timeframe: æ—¶é—´å‘¨æœŸ
            start_time: å¼€å§‹æ—¶é—´
            end_time: ç»“æŸæ—¶é—´
            limit: é™åˆ¶è®°å½•æ•°
            
        Returns:
            OHLCVæ•°æ®DataFrame
        """
        start_ms = int(start_time.timestamp() * 1000) if start_time else None
        end_ms = int(end_time.timestamp() * 1000) if end_time else None
        
        return self.db_manager.get_data(
            symbol=symbol,
            exchange=exchange,
            timeframe=timeframe,
            start_time=start_ms,
            end_time=end_ms,
            limit=limit
        )
    
    def clear_database(self, symbol: str = None, exchange: str = None, 
                      timeframe: str = None) -> int:
        """
        æ¸…ç†æ•°æ®åº“æ•°æ®
        
        Args:
            symbol: äº¤æ˜“å¯¹ç¬¦å·(å¯é€‰)
            exchange: äº¤æ˜“æ‰€(å¯é€‰)
            timeframe: æ—¶é—´å‘¨æœŸ(å¯é€‰)
            
        Returns:
            åˆ é™¤çš„è®°å½•æ•°
        """
        return self.db_manager.clear_data(symbol, exchange, timeframe)


def main():
    """å‘½ä»¤è¡Œæ¥å£"""
    parser = argparse.ArgumentParser(description='DataFeed Engine å‘½ä»¤è¡Œå·¥å…·')
    parser.add_argument('--action', choices=['stats', 'fetch', 'clear', 'start'], 
                        required=True, help='æ‰§è¡Œçš„æ“ä½œ')
    parser.add_argument('--config', help='é…ç½®æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--db', default='market_data.db', help='æ•°æ®åº“æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--symbol', help='äº¤æ˜“å¯¹ç¬¦å· (å¦‚: BTC/USDT)')
    parser.add_argument('--exchange', help='äº¤æ˜“æ‰€ (å¦‚: okx, binance, yahoo, tushare)')
    parser.add_argument('--timeframe', help='æ—¶é—´å‘¨æœŸ (å¦‚: 1m, 5m, 1h, 1d)')
    parser.add_argument('--days', type=int, default=7, help='è·å–å¤šå°‘å¤©çš„æ•°æ®')
    
    args = parser.parse_args()
    
    # å¦‚æœæ²¡æœ‰æŒ‡å®šé…ç½®æ–‡ä»¶ï¼Œä½¿ç”¨è„šæœ¬æ‰€åœ¨ç›®å½•çš„config.ini
    if not args.config:
        script_dir = os.path.dirname(os.path.abspath(__file__))
        args.config = os.path.join(script_dir, 'config.ini')
    
    # åˆå§‹åŒ–å¼•æ“
    try:
        engine = DataFeedEngine(db_path=args.db, config_path=args.config)
    except Exception as e:
        print(f"âŒ åˆå§‹åŒ–å¼•æ“å¤±è´¥: {e}")
        return 1
    
    if args.action == 'stats':
        # æ˜¾ç¤ºæ•°æ®åº“ç»Ÿè®¡ä¿¡æ¯
        try:
            info = engine.get_database_info()
            print("=" * 50)
            print("ğŸ“Š DataFeed Engine æ•°æ®åº“ç»Ÿè®¡")
            print("=" * 50)
            print(f"æ•°æ®åº“è·¯å¾„: {info['database_path']}")
            print(f"æ•°æ®åº“å¤§å°: {info['database_size'] / 1024:.2f} KB")
            print(f"æ€»è®°å½•æ•°: {info['total_records']:,}")
            
            if info['total_records'] > 0:
                print("\nğŸ“ˆ æŒ‰äº¤æ˜“æ‰€åˆ†å¸ƒ:")
                for exchange, count in info.get('records_by_exchange', {}).items():
                    print(f"  {exchange}: {count:,} æ¡è®°å½•")
                
                print("\nâ±ï¸ æŒ‰æ—¶é—´å‘¨æœŸåˆ†å¸ƒ:")
                for timeframe, count in info.get('records_by_timeframe', {}).items():
                    print(f"  {timeframe}: {count:,} æ¡è®°å½•")
                
                print("\nğŸ”¥ çƒ­é—¨äº¤æ˜“å¯¹ (å‰10):")
                for symbol, count in list(info.get('top_symbols', {}).items())[:10]:
                    print(f"  {symbol}: {count:,} æ¡è®°å½•")
            else:
                print("\nğŸ’¡ æ•°æ®åº“ä¸ºç©ºï¼Œä½¿ç”¨ --action fetch å¼€å§‹è·å–æ•°æ®")
            
        except Exception as e:
            print(f"âŒ è·å–ç»Ÿè®¡ä¿¡æ¯å¤±è´¥: {e}")
            return 1
    
    elif args.action == 'fetch':
        # è·å–æ•°æ®
        print("ğŸ”„ å¼€å§‹è·å–æ•°æ®...")
        
        try:
            if args.symbol and args.exchange:
                # è·å–æŒ‡å®šäº¤æ˜“å¯¹çš„æ•°æ®
                if args.exchange in ['okx', 'binance']:
                    results = engine.fetch_crypto_data(
                        symbols=[args.symbol],
                        timeframes=[args.timeframe] if args.timeframe else ['1h', '1d'],
                        exchanges=[args.exchange],
                        days=args.days
                    )
                    print(f"âœ… è·å–å®Œæˆ: {results}")
                elif args.exchange == 'yahoo':
                    results = engine.fetch_us_stock_data(
                        symbols=[args.symbol],
                        timeframes=[args.timeframe] if args.timeframe else ['1d'],
                        days=args.days
                    )
                    print(f"âœ… è·å–å®Œæˆ: æ’å…¥ {results} æ¡è®°å½•")
                elif args.exchange == 'tushare':
                    results = engine.fetch_a_stock_data(
                        symbols=[args.symbol],
                        timeframes=[args.timeframe] if args.timeframe else ['1d'],
                        days=args.days
                    )
                    print(f"âœ… è·å–å®Œæˆ: æ’å…¥ {results} æ¡è®°å½•")
            else:
                # è·å–æ‰€æœ‰é…ç½®çš„æ•°æ®
                results = engine.fetch_all_data()
                print(f"âœ… è·å–å®Œæˆ: {results}")
                
        except Exception as e:
            print(f"âŒ è·å–æ•°æ®å¤±è´¥: {e}")
            return 1
    
    elif args.action == 'clear':
        # æ¸…ç†æ•°æ®
        try:
            deleted_count = engine.clear_database(args.symbol, args.exchange, args.timeframe)
            print(f"âœ… å·²åˆ é™¤ {deleted_count} æ¡è®°å½•")
        except Exception as e:
            print(f"âŒ æ¸…ç†æ•°æ®å¤±è´¥: {e}")
            return 1
    
    elif args.action == 'start':
        # å¯åŠ¨å®šæ—¶ä»»åŠ¡
        print("ğŸš€ å¯åŠ¨DataFeed Engineå®šæ—¶ä»»åŠ¡...")
        try:
            engine.start_scheduler()
            print("âœ… å®šæ—¶ä»»åŠ¡å·²å¯åŠ¨ï¼ŒæŒ‰ Ctrl+C åœæ­¢")
            try:
                while True:
                    time.sleep(60)
            except KeyboardInterrupt:
                engine.stop_scheduler()
                print("\nâœ… å®šæ—¶ä»»åŠ¡å·²åœæ­¢")
        except Exception as e:
            print(f"âŒ å¯åŠ¨å®šæ—¶ä»»åŠ¡å¤±è´¥: {e}")
            return 1
    
    return 0


if __name__ == "__main__":
    sys.exit(main())
